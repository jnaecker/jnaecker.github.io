---
layout: page
title: Research
---

## Published and Accepted Manuscripts

#### [Observability Increases the Demand for Commitment Devices](http://bit.ly/commitment-paper-ssrn){:onClick="ga('send', 'event', 'Research', 'Download', this.href);"} **\[accepted at Management Science\]**

with Christine Exley

Previous research often interprets the choice to restrict one’s future opportunity set as evidence for sophisticated time-inconsistency. We propose an additional mechanism that may contribute to the demand for commitment technology: the desire to signal to others. We present a field experiment where participants can choose to give up money if they do not follow through with an action. When commitment choices are made public rather than kept private, we find significantly higher uptake rates.

## Working Papers

#### [The Lives of Others: Predicting Donations with Non-Choice Responses](http://bit.ly/donations-paper-ssrn){:onClick="ga('send', 'event', 'Research', 'Download', this.href);"} 

There is significant variation in the percentage of adults registered as organ donors across the United States. Some of this variation may be due to characteristics of the sign-up process, in particular the form that is used when state residents apply for or renew their driver's licenses. However, it is difficult to model and predict the success of the different forms with typical methods, due to the exceptionally large feature space and the limited data. To surmount this problem, I apply a methodology that uses data on subjective non-choice reactions to predict choices. I find that active (ie yes-no) framing of the designation question decreases designation rates by 2-3 percentage points relative to an opt-in framing. Additionally, I show that this methodology can predict behavior in an experimental setting involving social motives where we have good structural benchmarks. More generally, this methodology can be used to perform policy pseudo-experiments where field experiments would prove prohibitively expensive or difficult. 

#### [Do Hypothetical Choices and Non-Choice Ratings Reveal Preferences?](http://bit.ly/non-choice-paper-ssrn){:onClick="ga('send', 'event', 'Research', 'Download', this.href);"} 

with B. Douglas Bernheim, Daniel Bjorkgren, and Antonio Rangel

We develop a method for determining likely responses to a change in some economic condition (e.g., a policy) for settings in which either similar changes have not been observed, or it is challenging to identify observable exogenous causes of past changes. The method involves estimating statistical relationships across decision problems between choice frequencies and variables measuring non-choice reactions, and using those relationships along with additional non-choice data to predict choice frequencies under the envisioned conditions. In an experimental setting, we demonstrate that this method yields accurate measures of behavioral responses, while more standard methods are either inapplicable or highly inaccurate.


#### [Machine Learning and Behavioral Economics: Evaluating Models of Choice Under Risk and Ambiguity](http://bit.ly/ML-risk-paper-ssrn){:onClick="ga('send', 'event', 'Research', 'Download', this.href);"}

with Alex Peysakhovich **\[revise and resubmit at the Journal of Economic Behavior and Organization]**

There have been centuries of research on human choice under uncertainty. How far have we traveled? How can we incorporate new statistical methods into the search for good models? We use an online platform to collect a large data set of individuals indicating their willingness to pay to play uncertain lotteries and compare the performance of formal models to that of machine learning methods. We show that economic models tend to do worse out-of-sample than would be expected from their in-sample performance, so we argue that “in-sample variance explained” estimates should be taken with caution. In addition, models that attempt to fit a single risk profile to a large population do very poorly. However, a version of expected utility that allows for non-linear probability weighting (as in cumulative prospect theory) and individual-level parameters performs as well out-of-sample as machine learning techniques. The existence of such a simple-to-use and powerful model shows that there is likely little improvement to be made upon the state-of-the-art in the domain of simple risky gambles. On the other hand, we see that in the domain of ambiguity the most widely used models (a linear version of maximin preferences and second order expected utility) fail to compete with the machine learning methods. Combined with the ability of simple models to do well in the case of risk, we argue this suggests that building a portable ambiguity aversion model is a fruitful direction for both theorists and experimentalists alike. Our results highlight ways in which behavioral scientists can incorporate machine learning techniques in their daily practice to gain genuinely new insights. They also underscore the importance of looking out-of-sample when evaluating model quality.

## Work in Progress

#### What Drives Conspicuous Consumption? 
with James Andreoni, B. Douglas Bernheim, Christine Exley, and Paul Wong

#### Fairness and Time Inconsistency
with James Andreoni, Deniz Aydin, Blake Barton, and B. Douglas Bernheim

#### Incentives for Long-run Volunteer Behavior
with Christine Exley

#### Non-Choice Methods in Food and Gamble Decisions
with B. Douglas Bernheim, Christine Exley, Antonio Rangel, Charles Sprenger, and Neil Yu

<br>
Find me on [Google Scholar](http://scholar.google.com/citations?hl=en&user=v2-qGEAAAAAJ){:onClick="ga('send', 'event', 'Link', 'Click', this.href);"}, [RePeC](http://ideas.repec.org/f/pna439.html){:onClick="ga('send', 'event', 'Link', 'Click', this.href);"}, or [SSRN](http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1659584){:onClick="ga('send', 'event', 'Link', 'Click', this.href);"}.

